{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Web Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Web Data/europe_west.United_Kingdom.eng.1.IN.gz'\n",
    "def separate_data(file_path, out_path):\n",
    "    df = pd.read_csv(file_path, compression='gzip', header=0, sep='\\t', quotechar='\"')\n",
    "    df[['index', 'Date', 'Domain', 'N_Words', 'Text']] = df[',Date,Domain,N_Words,Text,Language,Score,Prediction'].str.split(',', n=4, expand=True)\n",
    "    df[['Text', 'Language', 'Score', 'Prediction']] = df['Text'].str.rsplit(',', n=3, expand=True)\n",
    "    df = df[['Text']]\n",
    "    df.to_csv(out_path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['Web Data/europe_east.Poland.pol.6.IN.gz', 'Web Data/europe_west.Finland.fin.3.IN.gz', 'Web Data/europe_west.Greece.ell.4.IN.gz', 'Web Data/europe_west.Portugal.por.2.IN.gz', 'Web Data/europe_west.United_Kingdom.eng.1.IN.gz']\n",
    "out_paths = ['Experiment Data/Web/PL/PL_Web.gz', 'Experiment Data/Web/FI/FI_Web.gz', 'Experiment Data/Web/EL/EL_Web.gz', 'Experiment Data/Web/PT/PT_Web.gz', 'Experiment Data/Web/EN/EN_Web.gz']\n",
    "for file, out in zip(file_paths, out_paths):\n",
    "    separate_data(file, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process TV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srt\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_subtitle_text(text):\n",
    "    # Remove substrings wrapped with <> or {}\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'\\{.*?\\}', '', text)\n",
    "    text = re.sub(r'♪.*?♪', '', text)\n",
    "    # Remove '- ' or ' -'\n",
    "    text = text.replace(' - ', '').replace('- ', '').replace(' -', '')\n",
    "    text = text.replace(' \\\" ', '').replace('\\\" ', '').replace(' \\\"', '').replace('\\\"', '')\n",
    "    text = text.replace('♪ ', '').replace(' ♪', '')\n",
    "    # Add space before and after punctuation marks\n",
    "    text = re.sub(r'([.,!?()])', r' \\1 ', text)\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    return text\n",
    "\n",
    "def srt_to_txt(srt_files, csv_file):\n",
    "    subtitles = []\n",
    "    for srt_file in srt_files:\n",
    "        with open(srt_file, 'r', encoding='utf-8') as f_in:\n",
    "            subs = list(srt.parse(f_in.read()))\n",
    "            for sub in subs:\n",
    "                new = clean_subtitle_text(sub.content)\n",
    "                if new != '':\n",
    "                    subtitles.append(clean_subtitle_text(sub.content))\n",
    "    df = pd.DataFrame(subtitles, columns=['Text'])\n",
    "    concat_rows = [' '.join(df['Text'][i:i+10]) for i in range(0, len(df), 10)]\n",
    "    # Create new DataFrame\n",
    "    new_df = pd.DataFrame({'Text': concat_rows})\n",
    "    new_df.to_csv(csv_file, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reality TV\\\\S1E1-ENG.srt', 'Reality TV\\\\S1E2-ENG.srt', 'Reality TV\\\\S1E3-ENG.srt', 'Reality TV\\\\S1E4-ENG.srt', 'Reality TV\\\\S1E5-ENG.srt', 'Reality TV\\\\S1E6-ENG.srt', 'Reality TV\\\\S1E7-ENG.srt', 'Reality TV\\\\S1E8-ENG.srt']\n",
      "Experiment Data/TV/EN/EN_TV.gz\n",
      "['Reality TV\\\\S1E1-FIN.srt', 'Reality TV\\\\S1E2-FIN.srt', 'Reality TV\\\\S1E3-FIN.srt', 'Reality TV\\\\S1E4-FIN.srt', 'Reality TV\\\\S1E5-FIN.srt', 'Reality TV\\\\S1E6-FIN.srt', 'Reality TV\\\\S1E7-FIN.srt', 'Reality TV\\\\S1E8-FIN.srt']\n",
      "Experiment Data/TV/FI/FI_TV.gz\n",
      "['Reality TV\\\\S1E1-GRE.srt', 'Reality TV\\\\S1E2-GRE.srt', 'Reality TV\\\\S1E3-GRE.srt', 'Reality TV\\\\S1E4-GRE.srt', 'Reality TV\\\\S1E5-GRE.srt', 'Reality TV\\\\S1E6-GRE.srt', 'Reality TV\\\\S1E7-GRE.srt']\n",
      "Experiment Data/TV/EL/EL_TV.gz\n",
      "['Reality TV\\\\S1E1-POR.srt', 'Reality TV\\\\S1E2-POR.srt', 'Reality TV\\\\S1E3-POR.srt', 'Reality TV\\\\S1E4-POR.srt', 'Reality TV\\\\S1E5-POR.srt', 'Reality TV\\\\S1E6-POR.srt', 'Reality TV\\\\S1E7-POR.srt', 'Reality TV\\\\S1E8-POR.srt']\n",
      "Experiment Data/TV/PT/PT_TV.gz\n",
      "['Reality TV\\\\S1E1-POL.srt', 'Reality TV\\\\S1E2-POL.srt', 'Reality TV\\\\S1E3-POL.srt', 'Reality TV\\\\S1E4-POL.srt', 'Reality TV\\\\S1E5-POL.srt', 'Reality TV\\\\S1E6-POL.srt', 'Reality TV\\\\S1E7-POL.srt']\n",
      "Experiment Data/TV/PL/PL_TV.gz\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "for input, output in zip(['ENG', 'FIN', 'GRE', 'POR', 'POL'], ['EN', 'FI', 'EL', 'PT', 'PL']):\n",
    "    srt_files = glob.glob(f'Reality TV/*{input}.srt')\n",
    "    output_file = f'Experiment Data/TV/{output}/{output}_TV.gz'\n",
    "    srt_to_txt(srt_files, output_file)\n",
    "    print(srt_files)\n",
    "    print(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Legal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove new line characters\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Add space before punctuation marks\n",
    "    text = re.sub(r'([.,!?()])', r' \\1 ', text)\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    return text\n",
    "\n",
    "def process_law_data(lang, output_file):\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset('multi_eurlex', language=lang, trust_remote_code=True)\n",
    "\n",
    "    # Convert to pandas DataFrame\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(dataset['train']),\n",
    "        pd.DataFrame(dataset['test']),\n",
    "        pd.DataFrame(dataset['validation'])\n",
    "    ])['text'].apply(clean_text).to_frame()\n",
    "\n",
    "    df.columns.values[0] = 'Text'\n",
    "    print(df.head())\n",
    "\n",
    "    df.to_csv(output_file, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text\n",
      "0  COMMISSION DECISION of 6 March 2006 establishi...\n",
      "1  Commission Regulation ( EC ) No 1330/2003 of 2...\n",
      "2  Council Regulation ( EC ) No 1786/2003 of 29 S...\n",
      "3  ***** COMMISSION REGULATION ( EEC ) No 2590/85...\n",
      "4  COMMISSION REGULATION ( EEC ) No 1103/93 of 30...\n",
      "                                                Text\n",
      "0  KOMISSION PÄÄTÖS , tehty 6 päivänä maaliskuuta...\n",
      "1  Komission asetus ( EY ) N:o 1330/2003 , annett...\n",
      "2  Neuvoston asetus ( EY ) N:o 1786/2003 , annett...\n",
      "3  KOMISSION ASETUS ( ETY ) N:o 2590/85 , annettu...\n",
      "4  KOMISSION ASETUS ( EY ) N:o 1038/2004 , annett...\n",
      "                                                Text\n",
      "0  ΑΠΌΦΑΣΗ ΤΗΣ ΕΠΙΤΡΟΠΉΣ της 6ης Μαρτίου 2006 για...\n",
      "1  Κανονισμός ( ΕΚ ) αριθ . 1330/2003 της Επιτροπ...\n",
      "2  Κανονισμός ( ΕΚ ) αριθ . 1786/2003 του Συμβουλ...\n",
      "3  ***** ΚΑΝΟΝΙΣΜΟΣ ( ΕΟΚ ) αριθ . 2590/85 ΤΗΣ ΕΠ...\n",
      "4  ΚΑΝΟΝΙΣΜΟΣ ( ΕΟΚ ) αριθ . 1103/93 ΤΗΣ ΕΠΙΤΡΟΠΗ...\n",
      "                                                Text\n",
      "0  DECISÃO DA COMISSÃO de 6 de Março de 2006 que ...\n",
      "1  Regulamento ( CE ) n . o 1330/2003 da Comissão...\n",
      "2  Regulamento ( CE ) n . o 1786/2003 do Conselho...\n",
      "3  REGULAMENTO ( CEE ) No 2590/85 DA COMISSÃO de ...\n",
      "4  REGULAMENTO ( CEE ) No 1103/93 DA COMISSÃO de ...\n",
      "                                                Text\n",
      "0  DECYZJA KOMISJI z dnia 6 marca 2006 r . ustana...\n",
      "1  Rozporządzenie Rady ( WE ) nr 1786/2003 z dnia...\n",
      "2  ROZPORZĄDZENIE KOMISJI ( WE ) NR 1038/2004 z d...\n",
      "3  Rozporządzenie Komisji ( WE ) nr 1012/2003 z d...\n",
      "4  Rozporządzenie Rady ( WE ) nr 2229/2003 z dnia...\n"
     ]
    }
   ],
   "source": [
    "for i in ['EN', 'FI', 'EL', 'PT', 'PL']:\n",
    "    process_law_data(i.lower(), f'Experiment Data/Legal/{i}/{i}_Law.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ling413env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
